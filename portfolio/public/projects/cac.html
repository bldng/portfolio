<p>Right now, it is highly likely that a newly developed application looks more like your worn out student budget leather couch than anything displayed in the 1968 science fiction movie 2001: A Space Odyssey.</p>
<p>How come?
It seems like we got stuck looking at screens. Ever since the television we are bound to glowing screens like moths, from gigantic CRT displays in the basement to the retina display in your pocket. Every new gadget comes with its own, new one. Hours and hours of work and resources spent on developing, designing, manufacturing – destined for en eternal existence on a landfill hopefully far away.</p>
<p>Sure, some services live &quot;in the cloud&quot;, enabling the access from multiple devices for on service, but still require your full attention – from installation over login and usage to deletion.</p>
<p>Nearly thirty years after the first screening of 2001: A Space Odyssey, Mark Weiser from Xerox PARC developed the idea of Ubiquitous Computing --- and the term Calm Technology. He argues that the perfect interface is an invisible one, and that the mentioned time that is spent on developing todays screen based interfaces is not at all leading into a desirable direction. Instead he says &quot;Attractiveness is the opposite of invisible&quot;.[1]
The idea there seems very appealing. A computer experience that is so subtle you forget it even exists. That really can&#39;t be said about the current state of technology. Blaring mobile devices that need and and sadly sometimes are given more attention than infants. Simultaneously, a mutated idea of ubiquitous computing called Internet of Things enables plants to use twitter and your body scale to post the state of your belly to your online profile. So does scientific progress, after all, really go &quot;boink&quot;?[3]</p>
<p>Sadly, Mark Weiser passed away in 1999 and leaves behind the vision of calm technology. But Donald Norman and others keep on further refining the the outlines of a desirable future on living with the increasing number of digital devices. One key element is to break with the traditional display itself, or as Norman puts it: </p>
<blockquote>
<blockquote>
<p>&quot;If I were to have my way, we would not see computer interfaces. In fact, we would not see computers: both the interface and the computer would be invisible, subservient to the task the person was attempting to accomplish.&quot;[8] </p>
</blockquote>
</blockquote>
<p>Or, more drastically, Weiser and Brown: </p>
<blockquote>
<blockquote>
<p>&quot;If computers are everywhere they better stay out of the way.&quot;[2]</p>
</blockquote>
</blockquote>
<p>But how is this goal achievable? One attempt was made by Rehman et al.[4] in 2000 where they experimented with augmented reality as substitute for the traditional display which certainly breaks with the traditional way,  but projecting the interface directly on your retina does not exactly count as being invisible. 
Further approaches to calm technology, or ambient intelligence are scattered around in various areas. For example machine learning algorithms warning you of potential credit card fraud, netflix recommendation system, the predictive interface in Wolfram&#39;s Mathematica 9 and of course the Google PageRank algorithm. 
Speaking of which, also developed Google Now, which is a relatively new service that goes into an interesting direction. </p>
<h3 id="siriously-">Siriously?</h3>
<p>Google Now is, similar to Apples Siri, an interactive service for mobile devices, proclaiming to be an &quot;intelligent personal assistant&quot;. What it does is aiding the user in day to day activities with preprogrammed patterns like showing attractions near you, reminding you of calendar events, etc. It has not reached its full potential yet, as it will grow with the further development of Knowledge Graph.
But do these services match the criteria of calm technology? 
I would argue they do not. 
Starting with the failure of being subtle or even invisible. They both live on a device that has to be taken care of, have to be administered and can&#39;t be trusted in their current state. Furthermore they are neither intelligent nor a personal assistant.
Whereas an intelligent system does not necessarily need an artificial consciousness, Google Now and Siri would need to adapt their behavior over time according to the fact that every user is an individual character with different needs that go far beyond finding a restaurant or setting timers. This adaption does not happen, but still both Apple and Google chose to use an anthropomorphic sonic interface that does not behave as the interface suggests. This becomes clear after a short time when the witty responses start to repeat. This is the ticket to a nice trip to the uncanny valley. Which is surprising, as many other companies learned to avoid this problem by using a metaphor, or more specifically zoomorphism, that does not suggest an equal counterpart like Sony&#39;s robotic pet Aibo or Toshiba&#39;s universal remote Apripoco. This briefly sums up the intelligence part.
As mentioned before, they both live on mobile devices exclusively, so the assistance stops working as soon as the user works on a different device like a workstation computer, the television, temperature regulation or lighting. This device (and display) agnosticism is a fundamental feature for a service that claims to be an assisting you. Another problem is that both services are by design not obedient to whomever they claim to assist. This obviously has to do with the limited featureset currently available, but also with a different topic named filter bubbling[5], which is a strategy to filter the content available to you on a basis you are not allowed to manipulate and certainly not your digital assistant programmed by the same company.</p>
<h3 id="we-need-to-talk-">We need to talk.</h3>
<p>In the book &quot;Next Nature&quot;[6], the authors Koert van Mensvoort and Hendrik-Jan Grievink have made an adaption of Maslow&#39;s hierarchy of needs, which I show here in a condensed version. Currently, no digital invention arrived at the &quot;invisible&quot; layer, but it seems the internet is on its way from the vital layer to join omnipresent technologies like money and handwriting.</p>
<table>
<thead>
<tr>
<th style="text-align:left">Maslow&#39;s hierarchy of needs</th>
<th style="text-align:left">Hierarchy of Technology</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">-</td>
<td style="text-align:left">(Natural)*</td>
</tr>
<tr>
<td style="text-align:left">Self-transcendence</td>
<td style="text-align:left">Invisible</td>
</tr>
<tr>
<td style="text-align:left">Self-actualization</td>
<td style="text-align:left">Vital</td>
</tr>
<tr>
<td style="text-align:left">Esteem</td>
<td style="text-align:left">Accepted</td>
</tr>
<tr>
<td style="text-align:left">Safety needs</td>
<td style="text-align:left">Applied</td>
</tr>
<tr>
<td style="text-align:left">Physiological needs</td>
<td style="text-align:left">Functional</td>
</tr>
</tbody>
</table>
<p><sub><em>* In brackets, as the book narrows technology not only to digital artifacts. If digital artifacts hold the potential to become a naturalized technology as agriculture, cooking or time is a question that would go beyond the scope of this essay.</em></sub></p>
<p>In the same book, Joran Damsteeg et al. have devised 11 Golden Rules of Anthropomorphism and Product Design[7]. A few have been addressed before, but I will quote them in their entirety and add more points that deem fundamental for a calmer execution of personal assistants.</p>
<p><strong>11 Golden Rules:</strong></p>
<ol>
<li>Any Association that Can be Made, Will be Made</li>
<li>Different People Anthropomorphize Differently</li>
<li>Keep it ASS. Abstract, Simple and Subtle</li>
<li>Complex Products Tend to Be Anthropomorphized</li>
<li>Consider Zoomorphism as an Alternative</li>
<li>Meet People’s Expectations</li>
<li>Respect Social Standards</li>
<li>Use Human Ethics</li>
<li>Be Aware of the Ecosystem You’re Invading</li>
<li>Enhance Human Experience, Don’t Replace It</li>
<li>Don’t Use Anthropomorphism if it Does Not Serve Any Purpose</li>
</ol>
<p><strong>Additional principles:</strong></p>
<ol>
<li>Exceptional Natural language processing (sarcasm, seriousness)</li>
<li>Ambient intelligence (IoT interface)</li>
<li>Device agnosticism</li>
<li>User always has override</li>
</ol>
<p>The first point mentions the human voice as as interface. This is not only a remnant of looking into Google Now and Siri. Altough Weiser said that even if it technically works, it would still be a conscious interaction and far from unobtrusive. 
He also holds this up against intelligent agents, as the relationship would put it too much in the center of attention[1]. </p>
<p>But still, I would argue this combination is the most precise and natural interface imaginable in the near future and reduces the time needed to concentrate to a minimum. Even a thought controlled interaction is still a conscious interaction by definition. Maybe my sight is too narrow here, but I can not imagine a more reduced interface than that. There only stays a solely autonomous system that we are not capable to interact with anymore. Furthermore, as anthropomorphobic reactions are lost over time, a voice based solution could be easier to adapt to than any visual representation. </p>
<p>The fourth point refers to the filter bubbles, which means the user should have the choice to bypass preprogrammed patterns when the situation demands it. Apart from that, the modulation of the input should influence the action and enable tasks being executed based on a calculated priority. This is not only applicable to voice input, as an example from the movie Johnny Mnemonic shows. When the character Takahashi ends a call, he does this with a wide sweeping arm gesture that leads to an ending of the call, but also to the retraction of the video phone into his desk. In the book &quot;Make it so --- Interaction Design Lessons from Science Fiction&quot; the authors Nathan Shedroff and Christopher Noessel add to this scene:</p>
<blockquote>
<blockquote>
<p>&quot;When technology allows for a range of inputs, users can channel emotion into them, making the input more than a control but also a medium of expression. If the degree of emotion affects the degree of system response, all the better. This means that the technology fits the way we communicate as people much more readily than the precision that best fits computers.&quot;[9]</p>
</blockquote>
</blockquote>
<p><strong>&quot;I don&#39;t understand this &#39;ass kicking&#39; reference, sir.&quot;</strong></p>
<p>Sadly, I am not aware of an existing system that matches these criterias, so once again Science Fiction has to serve as an example. 
One system, despite the added eye candy for entertainment, ticks off a lot of the points above and it is: J.A.R.V.I.S. from the newer Iron Man movie adaptations[10]. Originally a butler in the comic books, the film turned the character into a sophisticated intelligent assistant. It is device agnostic, as it lives in Tony Starks workshop, mobile devices and suits. It is also display agnostic and adapts the method to the intended usage (screen based, volumetric projection, voice only). J.A.R.V.I.S. also understands sarcasm and accepts overrides –– despite not being able to understand the logic or knowing it is mathematically impossible, which also makes sense metaphorically since the relationship emulates a master / butler affiliation.</p>
<blockquote>
<blockquote>
<p>&quot;Jarvis, remind me to develop a personality for you later.&quot;
<br>Tony Stark[11]</p>
</blockquote>
</blockquote>
<h3 id="references-">References:</h3>
<p>1 <a href="http://project.cyberpunk.ru/idb/ubicomp_world_is_not_desktop.html">http://project.cyberpunk.ru/idb/ubicomp_world_is_not_desktop.html</a><br>
2 <a href="http://www.johnseelybrown.com/calmtech.pdf">http://www.johnseelybrown.com/calmtech.pdf</a><br>
3 <a href="http://cdn0.sbnation.com/imported_assets/1025866/jon3_GIF.gif">http://cdn0.sbnation.com/imported_assets/1025866/jon3_GIF.gif</a><br>
4 <a href="http://www.cl.cam.ac.uk/research/dtg/www/files/publications/public/fms27/2002-RehmanStaCou-invisible.pdf">http://www.cl.cam.ac.uk/research/dtg/www/files/publications/public/fms27/2002-RehmanStaCou-invisible.pdf</a><br>
5 <a href="http://www.ted.com/talks/eli_pariser_beware_online_filter_bubbles.html">http://www.ted.com/talks/eli_pariser_beware_online_filter_bubbles.html</a><br>
6  Koert van Mensvoort, Hendrik-Jan Grievink &quot;Next Nature&quot;, Actar 2011, p.378-387<br>
7  ibid., p.378-387<br>
8 Norman, Donald A.: &quot;Why Interfaces Don&#39;t Work&quot; in Laurel, Brenda (ed.): The Art of HumanComputer Interface Design, Addison-Wesley, 1990, p.219<br>
9  Nathan Shedroff and Christopher Noessel: &quot;Make it so --- Interaction Design Lessons from Science Fiction&quot;, Rosenfeld Media 2012, p.214<br>
10 <a href="http://www.youtube.com/watch?v=mbj3XSvDyw8">http://www.youtube.com/watch?v=mbj3XSvDyw8</a><br>
11 <a href="http://www.imdb.com/title/tt1233205/">http://www.imdb.com/title/tt1233205/</a><br></p>
